{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisierung auf dem Titanic-Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinweis: Da das Notebook nur das Prinizip der Regularisierung zeigen soll, ist der ML-Worflow in diesem Notebook stark vereinfacht (d.h. kein Auffüllen von N/As, kein Feature-Scaling und keine kategorischen Features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # avoid slide-copy-warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Survived  Pclass   Age  SibSp  Parch     Fare\n0         0       3  22.0      1      0   7.2500\n1         1       1  38.0      1      0  71.2833\n2         1       3  26.0      0      0   7.9250\n3         1       1  35.0      1      0  53.1000\n4         0       3  35.0      0      0   8.0500",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selection = df[[\"Survived\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "df_selection = df_selection.dropna()\n",
    "df_selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_selection.drop(columns = [\"Survived\"])\n",
    "df_y = df_selection[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Ridge-Regularisierung\n",
    "1. Trainieren Sie eine Logistische Regression mit Ridge-Regularisierung (siehe [RidgeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)) mit $\\alpha =100$ auf den Trainingsdaten.\n",
    "2. Bestimmen Sie die Accuracy auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6713286713286714\n",
      "Pclass   -0.320888\n",
      "Age      -0.013431\n",
      "SibSp    -0.096943\n",
      "Parch     0.092842\n",
      "Fare      0.002719\n",
      "dtype: float64\n",
      "Summe der absoluten Gewichte 0.5268232381956689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge = RidgeClassifier(alpha=100, max_iter=1000)\n",
    "ridge.fit(X_train, y_train)\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, pred)))\n",
    "print(pd.Series(ridge.coef_[0], index = df_X.columns))\n",
    "print(\"Summe der absoluten Gewichte \" + str(sum(np.absolute(ridge.coef_[0]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Cross-Validation über $\\alpha$\n",
    "1. Führen Sie nun eine Cross-Validation mit Hilfe der Klasse [RidgeClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html) durch. Benutzen Sie dafür die gleichen Werte für $\\alpha$ wie in [diesem Notebook](https://github.com/pabair/ml-kurs/blob/master/4_Regularisierung%2BCV.ipynb) in Zelle 9.\n",
    "2. Bestimmen Sie die Accuracy auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 6\n",
      "Accuracy: 0.6853146853146853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "alphas = range(1,10000)\n",
    "ridgecv = RidgeClassifierCV(alphas = alphas)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "pred = ridgecv.predict(X_test)\n",
    "print(\"Alpha: \" + str(ridgecv.alpha_))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3:  Lasso-Regularisierung\n",
    "Für die Lasso-Regularisierung gibt es keine extra Unterklasse, da diese bei der Klasse `LogisitcRegression` über den Parameter `penalty` eingestellt werden kann. Mit dem Parameter `penalty = \"l1\"` wird die Lasso-Regression verwendet.\n",
    "Der Regularisierungsfaktor $\\alpha$ wird in diesem Fall über den Parameter `C` bestimmt, welcher den Default-Wert `C=1.0` hat:\n",
    "\n",
    "`LogisticRegression(max_iter=1000, penalty = \"l1\", C=1.0, solver=\"liblinear\")`\n",
    "\n",
    "Beachten Sie dabei:\n",
    "- Für die Regression ist das zusätzliche Argument `solver=\"liblinear\"` nötig, da der Standard-Optimierer nicht mit `L1` funktioniert.\n",
    "- Parameter `C` gibt die <ins>inverse</ins> Stärke der Regularisierung an (Details siehe [hier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)).\n",
    "\n",
    "\n",
    "1. Trainieren Sie eine Logistische Regression mit Lasso-Regression für verschiedene Parameter `C`:\n",
    "    - den Default-Wert `C=1.0`.\n",
    "    - wählen Sie `C` so, dass das Modell sehr stark regularisiert ist.\n",
    "    - wählen Sie `C` so, dass das Modell keine Regularisierung hat.\n",
    "2. Vergleiche Sie die Ergebnisse dieser Modelle indem Sie:\n",
    "    - die Gewichte und deren Summe ausgeben (wie in [diesem Notebook](https://github.com/pabair/ml-kurs/blob/master/4_Regularisierung%2BCV.ipynb)).\n",
    "    - die Accuracy auf den Testdaten ermitteln. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy normal: 0.6923076923076923\n",
      "Gewichte der Features:\n",
      "Pclass   -0.936400\n",
      "Age      -0.037640\n",
      "SibSp    -0.308794\n",
      "Parch     0.298053\n",
      "Fare      0.007302\n",
      "dtype: float64\n",
      "Summe der absoluten Gewichte 1.5881890748436096\n",
      "\n",
      "Accuracy strong: 0.5524475524475524\n",
      "Gewichte der Features:\n",
      "Pclass    0.0\n",
      "Age       0.0\n",
      "SibSp     0.0\n",
      "Parch     0.0\n",
      "Fare      0.0\n",
      "dtype: float64\n",
      "Summe der absoluten Gewichte 0.0\n",
      "\n",
      "Accuracy weak: 0.6853146853146853\n",
      "Gewichte der Features:\n",
      "Pclass   -1.052985\n",
      "Age      -0.041775\n",
      "SibSp    -0.336393\n",
      "Parch     0.327286\n",
      "Fare      0.005949\n",
      "dtype: float64\n",
      "Summe der absoluten Gewichte 1.7643873042701608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lasso = LogisticRegression(max_iter=1000, penalty = \"l1\", C= 1.0, solver=\"liblinear\")\n",
    "lasso_strongReg = LogisticRegression(max_iter=1000, penalty = \"l1\", C= 0.0001, solver=\"liblinear\")\n",
    "lasso_weakReg = LogisticRegression(max_iter=1000, penalty = \"l1\", C= 1000.0, solver=\"liblinear\")\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_strongReg.fit(X_train, y_train)\n",
    "lasso_weakReg.fit(X_train, y_train)\n",
    "\n",
    "pred1 = lasso.predict(X_test)\n",
    "pred2 = lasso_strongReg.predict(X_test)\n",
    "pred3 = lasso_weakReg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy normal: \" + str(accuracy_score(y_test, pred1)))\n",
    "print(\"Gewichte der Features:\")\n",
    "print(pd.Series(lasso.coef_[0], index = df_X.columns))\n",
    "print(\"Summe der absoluten Gewichte \" + str(sum(np.absolute(lasso.coef_[0]))))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Accuracy strong: \" + str(accuracy_score(y_test, pred2)))\n",
    "print(\"Gewichte der Features:\")\n",
    "print(pd.Series(lasso_strongReg.coef_[0], index = df_X.columns))\n",
    "print(\"Summe der absoluten Gewichte \" + str(sum(np.absolute(lasso_strongReg.coef_[0]))))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Accuracy weak: \" + str(accuracy_score(y_test, pred3)))\n",
    "print(\"Gewichte der Features:\")\n",
    "print(pd.Series(lasso_weakReg.coef_[0], index = df_X.columns))\n",
    "print(\"Summe der absoluten Gewichte \" + str(sum(np.absolute(lasso_weakReg.coef_[0]))))\n",
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4. Cross-Validierung über  `C`\n",
    "Ein guter Wert für `C` soll nun mit Hilfe der Methode `cross_val_score` gefunden werden. Ein Beispiel für diese Methode ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65217391 0.73684211 0.6754386  0.71929825 0.71052632]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, penalty = \"l1\", C=1.0, solver=\"liblinear\")\n",
    "accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Methode führt eine k-fold Cross-Validation auf den Trainingsdaten durch und gibt für jeden der k-folds den Score (in diesem Fall \"accuracy\") des Modell auf den jeweiligen Validierungsdaten zurück."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Berechnen Sie den Durchschnitt der Rückgabewerte von `cross_val_score` um für das gegebene `model` den durchschnittlichen Accuarcy-Score über alle k-folds zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6988558352402746"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import mean\n",
    "\n",
    "mean_accuracy = mean(accuracies)\n",
    "mean_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Berechnen Sie für jeden der Werte $ C \\in [0.1, 0.2, ...,9.8, 9.9]$ den durchschnittlichen Accuarcy-Score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953151653838151\n"
     ]
    }
   ],
   "source": [
    "mean_accuracies = []\n",
    "\n",
    "for c in range(1, 100):\n",
    "    model = LogisticRegression(max_iter=1000, penalty = \"l1\", C=c/10., solver=\"liblinear\")\n",
    "    accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    mean_accuracy = mean(accuracies)\n",
    "    mean_accuracies.append(mean_accuracy)\n",
    "\n",
    "print(mean(mean_accuracies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Trainieren Sie das Modell mit dem besten Wert für $C$ auf allen Trainingsdaten."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. Accur: 0.7216475972540046\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.3"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_accuracy = max(mean_accuracies)\n",
    "print(\"Max. Accur: \" + str(max_accuracy))\n",
    "max_index = np.argmax(mean_accuracies)\n",
    "max_C = (max_index+1) / 10\n",
    "max_C"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Bestimmen Sie die Accuracy dieses Modells auf den Testdaten."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000, penalty = \"l1\", C=max_C, solver=\"liblinear\")\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print(\"Accuracy : \" + str(accuracy_score(y_test, pred)))\n",
    "#0.6923076923076923\n",
    "#0.6923076923076923"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}